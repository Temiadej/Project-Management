# Open-Source Crisis Misinformation Response Network

**Natasha Nangia**  
Fall 2025

---

## Abstract

During crises such as natural disasters, public health emergencies, and humanitarian conflicts, people are often forced to make decisions with limited and rapidly changing information. In these moments, misinformation can spread quickly and cause real harm, especially when official communication is delayed or unclear. This paper presents a hypothetical Open-Source Crisis Misinformation Response Network (CMRN), a distributed system designed to help communities identify, verify, and respond to misinformation during crisis events. Rather than relying on centralized authorities or closed moderation systems, the project is built around open-source principles that emphasize transparency, shared responsibility, and public documentation. The focus of this paper is not on building a technical solution, but on explaining how such a network would be managed using working open and integrative project management concepts. By examining governance, contributor roles, workflows, feedback mechanisms, and sustainability, this paper explores how open project management can better support trust and adaptability in high-stakes crisis environments.

---

## Introduction

Crises create chaotic information environments and when disasters or public health emergencies occur, people urgently seek guidance, updates, and reassurance. At the same time, accurate information is often incomplete, delayed, or difficult to interpret. As a result, individuals turn to social media, group chats, and informal online sources, where rumors and misleading claims can spread quickly. The World Health Organization refers to this situation as an “infodemic”, highlighting how misinformation during crises can interfere with response efforts and increase public confusion (World Health Organization, 2020).
The challenge of crisis misinformation goes beyond technology. While automated detection tools and content moderation systems can help flag suspicious claims, they cannot fully account for context, uncertainty, or rapidly evolving conditions. Attempts to manage crisis information through centralized control often fail to keep up with the scale and speed of misinformation, and they can also face backlash if decisions appear unclear or politically motivated. UNESCO has noted that responses to misinformation that lack transparency or community involvement risk further damaging public trust during already fragile moments (UNESCO, 2020).
These challenges suggest that crisis misinformation should be approached as a coordination and governance problem rather than a purely technical one. Open and community-driven systems offer an alternative by allowing verification work to be shared across contributors while keeping decision-making visible. This paper introduces the Open-Source Crisis Misinformation Response Network as a hypothetical project designed to explore how working open principles can be applied to manage misinformation in crisis settings.

---

### Purpose and Goals

The purpose of the Open-Source Crisis Misinformation Response Network is to support more transparent and coordinated responses to misinformation during crises. The project is not designed to eliminate misinformation entirely or to act as a single authority on truth. Instead, its goal is to reduce harm by creating clear processes for identifying questionable claims, discussing available evidence, and documenting conclusions in a way that others can review and critique.
The project has several practical goals. First, it aims to lower the barrier for participation by allowing contributors with different levels of expertise to engage in meaningful ways. Second, it seeks to balance speed and accuracy by combining distributed human judgment with limited automation, ensuring that rapid responses do not sacrifice credibility. Third, the project emphasizes public documentation so that verification decisions, disagreements, and revisions remain visible. Finally, the network is designed to persist beyond a single crisis, using post-event reflection and feedback to improve how future misinformation is handled.

---

### Target Audience

The Open-Source Crisis Misinformation Response Network is intended for a broad set of participants and users. Contributors include volunteer fact-checkers, journalists, researchers, and technologists who are interested in supporting crisis response efforts. These contributors may have varying levels of availability and expertise, making it important for the project to support flexible participation and clearly defined roles.
The network is also designed to serve organizations such as non-governmental organizations, public health groups, and local response teams that rely on timely and accurate information. In addition, affected communities themselves are a key audience. By making verification processes transparent and accessible, the project aims to help individuals better evaluate the information they encounter during crises rather than asking them to trust a closed system without explanation.

---

### Project Scope

The scope of this project is intentionally limited to coordination, verification workflows, and documentation. The project focuses on creating shared processes for reporting potential misinformation, discussing evidence, and recording outcomes in a public and traceable way. It also includes mechanisms for updating or revising conclusions as new information becomes available, recognizing that crisis conditions are often fluid.
At the same time, the project does not attempt to act as a censorship tool or to replace existing institutions such as news organizations, emergency agencies, or social media platforms and it does not enforce compliance or issue any authoritative rulings. By clearly defining what the project does and does not do, the scope remains manageable while still addressing a critical gap in how misinformation is handled during crises.

---

## Working Open Approach

This network uses a working open approach because openness is necessary for the project to function at all. During crises, information changes quickly and people are often skeptical of how decisions are made. If verification work happens behind closed doors, it becomes harder for others to trust the outcome, especially when conclusions change over time. Keeping work visible helps reduce confusion and makes it easier to explain why certain decisions were made.
In practice, working open means that most activity in the network happens in shared, public spaces. When a claim is reported, other contributors can immediately see that it is being reviewed and follow the discussion as it develops. Evidence, sources, and disagreements are documented as part of the process rather than summarized after the fact. Decisions about how a claim is evaluated are recorded alongside the reasoning that led to them, which makes it easier for others to understand or challenge those decisions later.
Openness also supports how people participate in the network. Contributors are not assigned tasks or expected to follow a strict workflow. Instead, they can jump in where they feel useful, whether that means flagging a claim, adding a source, or helping clarify a summary. This kind of self-directed participation makes more sense during crises, when availability varies and contributors may only have limited time to engage.
Another important part of working open in this project is how uncertainty is handled. Crisis information is often incomplete or contradictory, especially early on. Rather than waiting for full certainty, the network documents what is known at a given moment and updates conclusions as new information becomes available. Corrections and revisions are treated as expected parts of the process, not as mistakes that need to be hidden. This makes it easier for contributors and outside readers to follow how understanding evolves over time.
Finally, working open shapes how accountability works in the network. Influence develops through consistent participation rather than formal authority. Contributors who explain their reasoning clearly and engage constructively tend to carry more weight in discussions, but their conclusions are never final or immune to challenge. Because decisions remain visible and revisable, accountability comes from shared scrutiny rather than enforcement. In a crisis context, this helps the network remain flexible while still taking responsibility for its work.

---

## Community and Participation Model

This network is built around the idea that people will engage in different ways, and often only for short periods of time. During a crisis, contributors are not sitting down to work on a long-term project. Most are reacting to information they see in real time, often while dealing with the crisis themselves. Because of this, the network is designed to accommodate brief, uneven, and unpredictable participation rather than sustained involvement from a fixed group of contributors.
Participation in the network is based on what someone is able to do at a given moment, rather than on formal roles. Some people may only submit a report when they encounter a misleading claim online. Others may take time to look for sources, compare accounts, or point out inconsistencies across platforms. A smaller group of contributors may help organize discussions, summarize conclusions, or flag when a claim needs further review. These patterns are expected to shift as a crisis unfolds, and the network does not assume that contributors will remain active throughout an entire event.
To make participation easier, the network prioritizes visibility over onboarding. New contributors can see how reports are submitted, how discussions unfold, and how conclusions are documented by looking at existing cases. This makes it possible to participate without extensive guidance or prior involvement. During a crisis, when time and attention are limited, being able to observe and imitate existing practices is often more effective than formal training or documentation.
Trust within the network develops through interaction rather than credentials. Contributors who consistently provide sources, explain their reasoning, and respond constructively to questions tend to be taken more seriously over time. At the same time, the network avoids treating professional status or institutional affiliation as automatic indicators of reliability. Local knowledge, firsthand experience, and contextual understanding can be just as important as formal expertise during emergencies. Keeping discussions open allows these different forms of knowledge to surface and be evaluated.
The community model also acknowledges that misinformation response can be exhausting. Contributors may encounter distressing content, public disagreement, or pressure to respond quickly. For this reason, responsibility is shared across the network rather than placed on individuals. Contributors are not expected to resolve every issue they engage with, and stepping back is treated as normal rather than as a failure. This approach helps reduce burnout and supports continued participation across multiple crisis events.

---

## Governance and Decision-Making

Governance within this network is designed to support timely decision-making without relying on a centralized authority. During crises, delays and rigid approval structures can be just as harmful as misinformation itself. At the same time, completely unstructured decision-making can lead to confusion, inconsistent outcomes, or loss of trust. The governance model for this network aims to balance speed and accountability by making decisions visible and reviewable rather than final and unquestionable.
Decisions in the network are made through open discussion rather than private moderation. When a reported claim is disputed, contributors discuss available evidence in a shared space, citing sources and explaining their reasoning. Rather than voting immediately or deferring to a single moderator, the network allows time for multiple perspectives to surface, especially when information is incomplete or evolving. This approach reflects the reality that crisis information is often uncertain and that premature certainty can be misleading.
Authority within the network develops through demonstrated participation rather than formal assignment. Contributors who consistently engage constructively, reference reliable sources, and help clarify complex situations tend to carry more influence in discussions over time. However, this influence does not translate into unchecked power. Even experienced contributors are expected to explain their reasoning publicly, and their conclusions can be questioned or revised as new information emerges. This helps prevent decisions from being treated as fixed or beyond scrutiny.
The network also includes mechanisms for escalation when consensus cannot be reached. If discussions stall or become contentious, contributors can flag a case for broader review, drawing in additional participants or temporarily deferring a conclusion until more evidence is available. In extreme cases, a claim may be labeled as unresolved rather than forced into a definitive category. This option acknowledges that uncertainty is sometimes the most honest outcome during rapidly changing situations, particularly in public health or disaster contexts (World Health Organization, 2020).
Importantly, governance decisions are documented alongside the discussions that produce them. Labels, summaries, and updates are linked to their supporting evidence and conversation history. This creates a record that allows others to understand not just what decision was made, but why it was made at that moment. If a decision later proves incorrect, the revision process is also documented, reinforcing the idea that correction is a normal and expected part of crisis response rather than a failure of governance.
By keeping decision-making open, traceable, and revisable, the governance model supports both accountability and adaptability. While disagreements and delays are unavoidable in crisis environments, this approach ensures that decisions remain grounded in shared reasoning and collective responsibility rather than opaque authority.

---

## Workflow, Tools, and Roadmaps

The workflow of the Open-Source Crisis Misinformation Response Network is designed to be simple, flexible, and easy to follow during high-pressure situations. Rather than relying on rigid processes or long approval chains, the network uses lightweight workflows that allow contributors to respond quickly while still maintaining coordination and traceability. The goal is not to optimize for perfect efficiency, but to make it clear where a claim is in the process and what work still needs to be done.
When a potential piece of misinformation is identified, it enters the network through a shared intake process. This may include a short description of the claim, where it was encountered, and why it appears questionable. Once logged, the claim becomes visible to other contributors, allowing them to add context, supporting evidence, or counterevidence without waiting for assignment. This visibility helps prevent duplicated effort and allows contributors to self-select tasks based on their availability and familiarity with the topic.
Verification work happens through open discussion threads attached to each claim. Contributors share sources, note contradictions, and flag uncertainties as information evolves. Rather than treating verification as a one-time step, the network treats it as an ongoing process that can change as new data becomes available. Claims may move between provisional states before reaching a more stable conclusion, reflecting the reality that crisis information is often incomplete or rapidly changing.
Once a working conclusion is reached, the outcome is summarized and documented in a clear, accessible format. These summaries include links to the supporting discussion and evidence, making it possible for others to understand how the conclusion was reached. If new information later contradicts the original assessment, the claim can be reopened and revised. This approach aligns with public health guidance that emphasizes continuous communication and correction during information crises (World Health Organization, 2020).
The network relies on a small set of shared tools to support coordination rather than control behavior. GitHub-style issue tracking is used to log claims and track their status, while discussion spaces support deliberation and evidence sharing. Simple project boards or kanban-style views help contributors see which claims are new, under review, or resolved. These tools are used to make work visible, not to enforce strict timelines or productivity targets.
Roadmaps in this project are intentionally short-term and event-driven. Instead of long-term feature plans, the network focuses on preparing for different types of crises by maintaining reusable workflows, documentation templates, and post-crisis review practices. After a major event, contributors reflect on what worked, what caused confusion, and where processes broke down. These reflections inform small adjustments to workflows rather than large structural overhauls, helping the network remain adaptable across different contexts and future crises.

---

## Project Phases and Lifecycle

Crises rarely unfold in a predictable way, and misinformation tends to appear in waves rather than all at once. Because of this, the network is set up to operate in repeating phases instead of following a traditional linear project plan. These phases reflect how the work actually happens before, during, and after a crisis, rather than how it might look on a fixed timeline.
The first phase takes place before a major crisis is actively unfolding. During this time, the network focuses on staying ready rather than expanding aggressively. Contributors review past cases, clean up documentation, and make small improvements to reporting and discussion workflows. The goal during this phase is not to build new features, but to make sure existing processes are clear and easy to use. When a crisis begins, people should be able to jump in quickly without having to learn complicated systems.
The active response phase begins once misinformation starts spreading during a crisis. This is when the network becomes more visible and more heavily used. Contributors log claims as they encounter them and help add context, sources, or corrections as information becomes available. Decisions during this phase are often tentative, since facts may still be emerging or changing. Rather than waiting for complete certainty, the network focuses on clearly communicating what is known, what is unclear, and what may need to be revisited as new information comes in (World Health Organization, 2020).
After the immediate pressure of a crisis has passed, the network moves into a post-crisis phase. Activity slows down, and contributors take time to look back at how the response unfolded. This includes reviewing major claims, noting where decisions were confusing or incorrect, and identifying parts of the workflow that caused delays or frustration. The purpose of this phase is not to assign blame, but to understand what worked and what did not so the network can improve for the next event.
These phases are not rigid or strictly separated. Some crises overlap, while others fade and resurface over time. The lifecycle model is meant to provide a shared understanding of priorities rather than a strict schedule. By treating crisis response as a repeating process instead of a one-off effort, the network stays flexible and better prepared to handle future misinformation events.

---

## Feedback, Iteration, and Learning

Since crisis misinformation is unpredictable, the Open-Source Crisis Misinformation Response Network is designed to learn from each event rather than assume it will get everything right the first time. Feedback and iteration are treated as normal parts of the project, not as signals that something has gone wrong. The goal is to gradually improve how the network responds across different crises, not to create a perfect process upfront.
Feedback comes from several sources during and after a crisis. Contributors often raise concerns directly in discussion threads when parts of the workflow feel confusing or when decisions are difficult to justify. Patterns also become visible over time, such as claims that repeatedly stall, sources that cause disagreement, or moments when information changes faster than the network can keep up. These observations are just as valuable as formal outcomes, since they highlight where the process itself needs adjustment.
After a major crisis, contributors take time to reflect on how the response unfolded. This usually happens once activity has slowed and there is more space to look back without pressure. During this period, the network reviews a small number of representative cases rather than trying to evaluate everything. The focus is on identifying recurring issues, such as unclear documentation, slow handoffs, or uncertainty about when a claim should be considered resolved. These reflections are documented so they can inform future responses instead of being forgotten once the crisis fades.
Iteration in the network is intentionally incremental. Rather than making large structural changes, contributors focus on small adjustments that reduce friction or confusion. This might include clarifying how claims are labeled, simplifying reporting templates, or adjusting how unresolved cases are handled. Keeping changes small helps ensure that improvements are actually adopted and understood, especially since many contributors may only engage occasionally.
Automation plays a limited role in this process. Automated tools may help surface patterns, flag repeated claims, or highlight sudden spikes in misinformation, but they do not make final decisions. Automation is treated as a way to support human attention rather than replace judgment. This is especially important in crisis settings, where context and nuance often matter more than speed alone. Any automated support used by the network is evaluated during post-crisis reflection to determine whether it genuinely helped or created additional confusion.
Overall, feedback and iteration allow the network to evolve without becoming rigid or overly complex. By making learning an explicit part of the project, the network stays responsive to new challenges while avoiding the assumption that any single response model will work in every crisis.

---

## Sustainability, Risks, and Limitations

The Open-Source Crisis Misinformation Response Network is not guaranteed to work smoothly or consistently over time, and that is something the project has to acknowledge upfront. Crisis response is unpredictable, and the people involved in this network are not full-time staff. Participation depends on availability, energy, and interest, all of which can change quickly, especially during stressful events.
One of the biggest risks for the project is burnout. Contributors may be exposed to upsetting content, constant disagreement, or pressure to respond quickly. Over time, this can make it harder for people to stay involved. The network tries to address this by avoiding rigid expectations. No one is expected to stay active forever, and stepping away after a crisis is normal. Responsibilities are shared, and unfinished work is treated as part of the process rather than a failure of individual contributors.
Another challenge is how the network’s work is perceived by people outside of it. Because the project operates in the open and documents uncertainty, some users may expect clearer or more definitive answers than the network can realistically provide. Others may disagree with how a claim is evaluated or feel frustrated when a conclusion changes. While the network cannot prevent this kind of criticism, keeping reasoning visible and clearly explaining why decisions change helps reduce confusion and misplaced blame.
The project is also limited in how much it can handle at once. During large crises, misinformation can spread faster than contributors can reasonably review. In those moments, the network cannot cover everything. Instead, it focuses on claims that appear widely shared or potentially harmful. This means that some misinformation will go undocumented, which is not ideal, but is more realistic than pretending the network can respond to every claim equally.
Finally, the network does not have the ability to enforce outcomes. It cannot remove content, require platforms to act, or compel people to trust its conclusions. Its impact depends on whether others find its work useful and credible. This limitation is intentional. By focusing on coordination, documentation, and clarity rather than enforcement, the project avoids taking on responsibilities it cannot realistically fulfill.

---

## Conclusion

This paper outlined a hypothetical Open-Source Crisis Misinformation Response Network and focused on how it would be managed rather than on proposing a perfect solution to misinformation itself. The project is built around the idea that misinformation during crises is messy, fast-moving, and difficult to control, which makes traditional centralized approaches ineffective. Instead of trying to eliminate misinformation or enforce definitive answers, the network prioritizes coordination, transparency, and shared responsibility.
By using a working open approach, the network allows contributors to see how decisions are made, challenge conclusions, and adapt as information changes. The emphasis on flexible participation, open governance, and lightweight workflows reflects the realities of crisis response, where contributors may only be involved briefly and where uncertainty is unavoidable. Treating correction and revision as expected outcomes helps the network remain credible without pretending to offer certainty where it does not exist.
The project’s phased lifecycle and focus on feedback highlight that effective crisis response is not about getting everything right in the moment, but about learning over time. Each crisis becomes an opportunity to improve processes, clarify documentation, and better support future responses. At the same time, the paper acknowledges clear limits around scale, sustainability, and authority, reinforcing that the network is meant to complement existing institutions rather than replace them.
Overall, the Open-Source Crisis Misinformation Response Network serves as an example of how open-source project management principles can be applied outside of traditional software development. By focusing on openness, coordination, and adaptability, the project demonstrates how working open approaches can support more thoughtful and resilient responses to complex, high-stakes problems like crisis misinformation.

---

## References

Alicea, B. (2025). IS 340: Project management lecture slides (Lectures 1–25). University of Illinois at Urbana-Champaign.
UNESCO. (2020). Communication and Information: Response to COVID-19 | UNESCO. Www.unesco.org. https://www.unesco.org/en/covid-19/communication-and-information-response
World Health Organization. (2020). Infodemic. Www.who.int. https://www.who.int/health-topics/infodemic/understanding-the-infodemic-and-misinformation-in-the-fight-against-covid-19#tab=tab_1
